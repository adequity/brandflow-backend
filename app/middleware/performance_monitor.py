"""
ê³ ê¸‰ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
- API ì‘ë‹µ ì‹œê°„ ì¶”ì 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§  
- ëŠë¦° ì¿¼ë¦¬ ê°ì§€
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
"""

import time
import asyncio
import psutil
import json
from datetime import datetime
from typing import Dict, List
from collections import defaultdict, deque
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response
from sqlalchemy import event
from sqlalchemy.engine import Engine

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'requests_total': 0,
            'requests_per_endpoint': defaultdict(int),
            'response_times': defaultdict(deque),
            'slow_queries': deque(maxlen=100),
            'error_count': defaultdict(int),
            'memory_usage': deque(maxlen=100),
            'active_connections': 0,
        }
        
        # ìµœê·¼ 100ê°œ ìš”ì²­ì˜ ì‘ë‹µì‹œê°„ë§Œ ë³´ê´€
        for endpoint_times in self.metrics['response_times'].values():
            endpoint_times = deque(maxlen=100)
    
    def record_request(self, endpoint: str, method: str, duration: float, status_code: int):
        """API ìš”ì²­ ì„±ëŠ¥ ê¸°ë¡"""
        self.metrics['requests_total'] += 1
        self.metrics['requests_per_endpoint'][f"{method} {endpoint}"] += 1
        self.metrics['response_times'][endpoint].append(duration)
        
        if status_code >= 400:
            self.metrics['error_count'][status_code] += 1
    
    def record_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        memory_info = psutil.Process().memory_info()
        self.metrics['memory_usage'].append({
            'timestamp': datetime.now().isoformat(),
            'rss': memory_info.rss / 1024 / 1024,  # MB
            'vms': memory_info.vms / 1024 / 1024,   # MB
        })
    
    def get_endpoint_stats(self, endpoint: str) -> Dict:
        """íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ í†µê³„"""
        times = list(self.metrics['response_times'][endpoint])
        if not times:
            return {'count': 0, 'avg': 0, 'min': 0, 'max': 0}
            
        return {
            'count': len(times),
            'avg': sum(times) / len(times),
            'min': min(times),
            'max': max(times),
            'p95': sorted(times)[int(len(times) * 0.95)] if len(times) > 20 else max(times)
        }
    
    def get_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ í†µê³„"""
        self.record_memory_usage()
        
        # ê°€ì¥ ëŠë¦° ì—”ë“œí¬ì¸íŠ¸ë“¤
        slow_endpoints = []
        for endpoint, times in self.metrics['response_times'].items():
            if times:
                avg_time = sum(times) / len(times)
                if avg_time > 0.1:  # 100ms ì´ìƒ
                    slow_endpoints.append({
                        'endpoint': endpoint,
                        'avg_time': round(avg_time, 3),
                        'count': len(times)
                    })
        
        slow_endpoints.sort(key=lambda x: x['avg_time'], reverse=True)
        
        return {
            'total_requests': self.metrics['requests_total'],
            'active_connections': self.metrics['active_connections'],
            'slow_endpoints': slow_endpoints[:5],
            'error_rates': dict(self.metrics['error_count']),
            'memory_mb': list(self.metrics['memory_usage'])[-1] if self.metrics['memory_usage'] else None,
            'slow_queries_count': len(self.metrics['slow_queries'])
        }

# ì „ì—­ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
performance_monitor = PerformanceMonitor()

class PerformanceMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, monitor: PerformanceMonitor):
        super().__init__(app)
        self.monitor = monitor
    
    async def dispatch(self, request: Request, call_next):
        # ìš”ì²­ ì‹œì‘ ì‹œê°„
        start_time = time.time()
        self.monitor.metrics['active_connections'] += 1
        
        try:
            # ìš”ì²­ ì²˜ë¦¬
            response = await call_next(request)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            duration = time.time() - start_time
            endpoint = request.url.path
            method = request.method
            status_code = response.status_code
            
            self.monitor.record_request(endpoint, method, duration, status_code)
            
            # ì‘ë‹µ í—¤ë”ì— ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
            response.headers["X-Response-Time"] = f"{duration:.3f}s"
            response.headers["X-Process-Memory"] = f"{psutil.Process().memory_info().rss / 1024 / 1024:.1f}MB"
            
            # ëŠë¦° ìš”ì²­ ê²½ê³ 
            if duration > 1.0:  # 1ì´ˆ ì´ìƒ
                print(f"ğŸŒ ëŠë¦° ìš”ì²­ ê°ì§€: {method} {endpoint} - {duration:.3f}s")
            
            return response
            
        except Exception as e:
            duration = time.time() - start_time
            self.monitor.record_request(request.url.path, request.method, duration, 500)
            raise e
            
        finally:
            self.monitor.metrics['active_connections'] -= 1

# SQLAlchemy ì¿¼ë¦¬ ëª¨ë‹ˆí„°ë§
@event.listens_for(Engine, "before_cursor_execute")
def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    context._query_start_time = time.time()

@event.listens_for(Engine, "after_cursor_execute") 
def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - context._query_start_time
    
    # ëŠë¦° ì¿¼ë¦¬ ê¸°ë¡ (100ms ì´ìƒ)
    if total > 0.1:
        performance_monitor.metrics['slow_queries'].append({
            'query': statement[:200] + '...' if len(statement) > 200 else statement,
            'duration': round(total, 3),
            'timestamp': datetime.now().isoformat(),
            'parameters': str(parameters)[:100] if parameters else None
        })
        print(f"ğŸŒ ëŠë¦° ì¿¼ë¦¬: {total:.3f}s - {statement[:100]}...")